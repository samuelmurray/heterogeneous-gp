{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mixed Likelihood GPLVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from IPython import display\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import tfgp\n",
    "    from tfgp.util import data\n",
    "    from tfgp.model import MLGPLVM\n",
    "    print(f\"Succesfully imported package: {tfgp.__file__}\")\n",
    "except ModuleNotFoundError:\n",
    "    import sys\n",
    "    import os\n",
    "    tfgpdir = os.path.abspath(\"../..\")\n",
    "    sys.path.append(tfgpdir)\n",
    "    import tfgp\n",
    "    from tfgp.util import data\n",
    "    from tfgp.model import MLGPLVM\n",
    "    print(f\"Package not found, adding project root to python path and import: {tfgp.__file__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_data = 100\n",
    "latent_dim = 2\n",
    "y, likelihoods, labels = data.make_oilflow(num_data)\n",
    "x = tfgp.util.PCA_reduce(y, latent_dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel = tfgp.kernel.ARDRBF(variance=0.5, gamma=0.5, xdim=2, name=\"kernel\")\n",
    "m = MLGPLVM(y, latent_dim, x=x, kernel=kernel, likelihoods=likelihoods)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = tf.losses.get_total_loss()\n",
    "learning_rate = 1e-4\n",
    "with tf.name_scope(\"train\"):\n",
    "    trainable_vars = tf.trainable_variables()\n",
    "    optimizer = tf.train.RMSPropOptimizer(learning_rate, name=\"RMSProp\")\n",
    "    train_all = optimizer.minimize(loss, \n",
    "                                   var_list=tf.trainable_variables(),\n",
    "                                   global_step=tf.train.create_global_step(),\n",
    "                                   name=\"train\")\n",
    "\n",
    "with tf.name_scope(\"summary\"):\n",
    "    m.create_summaries()\n",
    "    tf.summary.scalar(\"total_loss\", loss, family=\"Loss\")\n",
    "    for reg_loss in tf.losses.get_regularization_losses():\n",
    "        tf.summary.scalar(f\"{reg_loss.name}\", reg_loss, family=\"Loss\")\n",
    "    merged_summary = tf.summary.merge_all()\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run optimisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(x, z=None, *, loss):\n",
    "    plt.scatter(*x.T, c=labels, cmap=\"Paired\", edgecolors='k')\n",
    "    if z is not None:\n",
    "        ax1.scatter(*z.T, c=\"k\", marker=\"x\")\n",
    "    ax1.set_title(f\"Step {i}\")\n",
    "    ax2.set_title(f\"Loss: {train_loss}\")\n",
    "    ax2.plot(*np.array(loss).T)\n",
    "    display.display(f)\n",
    "    display.clear_output(wait=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, (ax1, ax2) = plt.subplots(1, 2)\n",
    "log_dir = f\"../../log/mlgplvm/{time.strftime('%Y%m%d%H%M%S')}\"\n",
    "loss_list = []\n",
    "n_iter = 1000\n",
    "n_print = 200\n",
    "try:\n",
    "    summary_writer = tf.summary.FileWriter(log_dir, sess.graph)\n",
    "    sess.run(init)\n",
    "    for i in range(n_iter):\n",
    "        sess.run(train_all)\n",
    "        if i % n_print == 0:\n",
    "            run_options = tf.RunOptions(trace_level=tf.RunOptions.FULL_TRACE)\n",
    "            run_metadata = tf.RunMetadata()\n",
    "            train_loss, summary = sess.run([loss, merged_summary], options=run_options, run_metadata=run_metadata)\n",
    "            summary_writer.add_run_metadata(run_metadata, f\"step{i}\")\n",
    "            summary_writer.add_summary(summary, i)\n",
    "            x_mean = m.qx_mean.eval()\n",
    "            z = m.z.eval()\n",
    "            loss_list.append([i, train_loss])\n",
    "            plot(x_mean, z, loss=loss_list)\n",
    "            ax1.cla()\n",
    "            ax2.cla()\n",
    "except KeyboardInterrupt:\n",
    "    pass\n",
    "finally:\n",
    "    x_mean = m.qx_mean.eval()\n",
    "    z = m.z.eval()\n",
    "    loss_list.append([i, loss.eval()])\n",
    "    plot(x_mean, z, loss=loss_list)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
