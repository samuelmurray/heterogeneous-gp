{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split = \"train\"\n",
    "path_to_data = os.path.abspath(f\"/Users/samuelmu/Data/mimic3-benchmarks/data/in-hospital-mortality/{split}\")\n",
    "file_ending = \"timeseries.csv\"\n",
    "label_file_name = \"listfile.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_file_paths = [os.path.join(path_to_data, f) for f in os.listdir(path_to_data) if f.endswith(file_ending)]\n",
    "label_file_path = os.path.join(path_to_data, label_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(data_file_paths[0])\n",
    "data = np.zeros((len(data_file_paths), df.shape[1] + 1), dtype=object)\n",
    "labels = pd.read_csv(label_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, f in enumerate(data_file_paths):\n",
    "    if i % 1000 == 0:\n",
    "        print(i)\n",
    "    df = pd.read_csv(f)\n",
    "    label = labels[labels[\"stay\"]==os.path.basename(data_file_paths[i])].values[0, 1]\n",
    "    data[i, -1] = label\n",
    "    for j, col in enumerate(df):\n",
    "        if type(df[col][0]) is np.float64:\n",
    "            data[i, j] = df[col].mean()\n",
    "        else:\n",
    "            data[i, j] = df[col].mode()[0]\n",
    "print(i)\n",
    "print(\"DONE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eye_opening_dict = {\n",
    "    \"no response\": 1, \n",
    "    \"to pain\": 2, \n",
    "    \"to speech\": 3, \n",
    "    \"spontaneously\": 4, \n",
    "    \"none\": np.nan,\n",
    "}\n",
    "\n",
    "motor_response_dict = {\n",
    "    \"no response\": 1, \n",
    "    \"abnorm extensn\": 2, \"abnormal extension\": 2, \n",
    "    \"abnorm flexion\": 3, \"abnormal flexion\": 3,\n",
    "    \"flex-withdraw\": 4, \n",
    "    \"localizes pain\": 5,\n",
    "    \"obeys commands\": 6,\n",
    "    \"none\": np.nan,\n",
    "}\n",
    "\n",
    "verbal_response_dict = {\n",
    "    \"no response\": 1,\n",
    "    \"incomp sounds\": 2, \"incomprehensible sounds\": 2,\n",
    "    \"inapprop words\": 3, \"inappropriate words\": 3,\n",
    "    \"confused\": 4,\n",
    "    \"oriented\": 5,\n",
    "    \"et/trach\": 6,\n",
    "    \"none\": np.nan,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert Eye Opening to integers\n",
    "col = 4\n",
    "for i in range(data.shape[0]):\n",
    "    if isinstance(data[i, col], str):\n",
    "        for k in eye_opening_dict:\n",
    "            if k in data[i, col].lower():\n",
    "                data[i, col] = eye_opening_dict[k]\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert Motor Response to integers\n",
    "col = 5\n",
    "for i in range(data.shape[0]):\n",
    "    if isinstance(data[i, col], str):\n",
    "        for k in motor_response_dict:\n",
    "            if k in data[i, col].lower():\n",
    "                data[i, col] = motor_response_dict[k]\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert Verbal Response to integers\n",
    "col = 7\n",
    "for i in range(data.shape[0]):\n",
    "    if isinstance(data[i, col], str):\n",
    "        for k in verbal_response_dict:\n",
    "            if k in data[i, col].lower():\n",
    "                data[i, col] = verbal_response_dict[k]\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered = pd.DataFrame(data[:, 1:], dtype=float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered.to_csv(f\"mimic_{split}.csv\", header=False, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "nor nor nor cat4 cat6 nor cat6 nor nor nor nor nor nor nor nor nor nor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tot_dim = 1 + 1 + 1 + 4 + 6 + 1 + 6 + 1 + 1 + 1 + 1 + 1 + 1 + 1 + 1 + 1 + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_onehot = np.zeros([data.shape[0], tot_dim + 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_onehot[:, 0] = data[:, 1]\n",
    "data_onehot[:, 1] = data[:, 2]\n",
    "data_onehot[:, 2] = data[:, 3]\n",
    "data_onehot[:, 3] = data[:, 4] == 1\n",
    "data_onehot[:, 4] = data[:, 4] == 2\n",
    "data_onehot[:, 5] = data[:, 4] == 3\n",
    "data_onehot[:, 6] = data[:, 4] == 4\n",
    "data_onehot[:, 7] = data[:, 5] == 1\n",
    "data_onehot[:, 8] = data[:, 5] == 2\n",
    "data_onehot[:, 9] = data[:, 5] == 3\n",
    "data_onehot[:, 10] = data[:, 5] == 4\n",
    "data_onehot[:, 11] = data[:, 5] == 5\n",
    "data_onehot[:, 12] = data[:, 5] == 6\n",
    "data_onehot[:, 13] = data[:, 6]\n",
    "data_onehot[:, 14] = data[:, 7] == 1\n",
    "data_onehot[:, 15] = data[:, 7] == 2\n",
    "data_onehot[:, 16] = data[:, 7] == 3\n",
    "data_onehot[:, 17] = data[:, 7] == 4\n",
    "data_onehot[:, 18] = data[:, 7] == 5\n",
    "data_onehot[:, 19] = data[:, 7] == 6\n",
    "data_onehot[:, 20] = data[:, 8]\n",
    "data_onehot[:, 21] = data[:, 9]\n",
    "data_onehot[:, 22] = data[:, 10]\n",
    "data_onehot[:, 23] = data[:, 11]\n",
    "data_onehot[:, 24] = data[:, 12]\n",
    "data_onehot[:, 25] = data[:, 13]\n",
    "data_onehot[:, 26] = data[:, 14]\n",
    "data_onehot[:, 27] = data[:, 15]\n",
    "data_onehot[:, 28] = data[:, 16]\n",
    "data_onehot[:, 29] = data[:, 17]\n",
    "data_onehot[:, 30] = data[:, 18]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set missing categorical variables to nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_onehot[np.isnan(data[:, 4].astype(float)), 3] = np.nan\n",
    "data_onehot[np.isnan(data[:, 4].astype(float)), 4] = np.nan\n",
    "data_onehot[np.isnan(data[:, 4].astype(float)), 5] = np.nan\n",
    "data_onehot[np.isnan(data[:, 4].astype(float)), 6] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_onehot[np.isnan(data[:, 5].astype(float)), 7] = np.nan\n",
    "data_onehot[np.isnan(data[:, 5].astype(float)), 8] = np.nan\n",
    "data_onehot[np.isnan(data[:, 5].astype(float)), 9] = np.nan\n",
    "data_onehot[np.isnan(data[:, 5].astype(float)), 10] = np.nan\n",
    "data_onehot[np.isnan(data[:, 5].astype(float)), 11] = np.nan\n",
    "data_onehot[np.isnan(data[:, 5].astype(float)), 12] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_onehot[np.isnan(data[:, 7].astype(float)), 14] = np.nan\n",
    "data_onehot[np.isnan(data[:, 7].astype(float)), 15] = np.nan\n",
    "data_onehot[np.isnan(data[:, 7].astype(float)), 16] = np.nan\n",
    "data_onehot[np.isnan(data[:, 7].astype(float)), 17] = np.nan\n",
    "data_onehot[np.isnan(data[:, 7].astype(float)), 18] = np.nan\n",
    "data_onehot[np.isnan(data[:, 7].astype(float)), 19] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_onehot = pd.DataFrame(data_onehot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_onehot.to_csv(f\"mimic_onehot_{split}.csv\", header=False, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
